{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Different Evalution Functions\n",
    "1. Automatically select 10 best generators\n",
    "2. Generate 20 parameter sets for each generator (directly from generator)\n",
    "3. Simulate bioreactor to see the final concentration\n",
    "4. Calculate scoring function and find 3 most fitted ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the parent directory to the PYTHONPATH\n",
    "sys.path.append(os.path.abspath('../'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate Parameter Set Using Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from configparser import ConfigParser\n",
    "from renaissance.evostrat.init_mlp import MLP\n",
    "from renaissance.tools.helper import load_pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Prameters from the repeat XX generation XX\n",
    "repeat = 7\n",
    "generation = 21\n",
    "cond_class = 1\n",
    "\n",
    "# \n",
    "lnminkm = -25\n",
    "lnmaxkm = 0\n",
    "\n",
    "pf_flag = 0\n",
    "base = \"../models/\"\n",
    "met_model = \"ecoli_shikki_regulation\"\n",
    "names_km = load_pkl(f'{base}/{met_model}/parameters/generated_k_names.pkl')\n",
    "\n",
    "n_sets = 10\n",
    "path_to_weights = f\"../output/rnsc_opt/repeat_{repeat}/weights_{generation}.pkl\"\n",
    "output_name = \"gen_x_parameters\"\n",
    "ss_idx = 1712\n",
    "\n",
    "#Parse arguments from configfile\n",
    "configs = ConfigParser()\n",
    "configs.read('configfile.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(cond_class, lnminkm, lnmaxkm, n_sets, names_km, len(names_km), param_fixing=pf_flag)\n",
    "\n",
    "# Load saved weights and generate\n",
    "opt_weights = load_pkl(path_to_weights)\n",
    "mlp.generator.set_weights(opt_weights)\n",
    "gen_params = mlp.sample_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load Model and Prepare Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytfa.io.json import load_json_model\n",
    "from skimpy.core import *\n",
    "from skimpy.mechanisms import *\n",
    "from skimpy.sampling.simple_parameter_sampler import SimpleParameterSampler\n",
    "from skimpy.io.yaml import load_yaml_model\n",
    "from skimpy.io.regulation import load_enzyme_regulation\n",
    "from skimpy.analysis.oracle.load_pytfa_solution import load_fluxes, load_concentrations, load_equilibrium_constants\n",
    "from skimpy.core.parameters import ParameterValues, ParameterValuePopulation\n",
    "from renaissance.kinetics.eigenvalue_calculation import calc_eigenvalues\n",
    "import renaissance.tools.helper as hp \n",
    "from renaissance.evostrat.init_mlp import MLP\n",
    "''' Run parameters and paths '''\n",
    "# Cellular parameters\n",
    "CONCENTRATION_SCALING = 1e9  # 1 mol to 1 mmol\n",
    "TIME_SCALING = 1  # 1hr\n",
    "DENSITY = 1105  # g/L\n",
    "GDW_GWW_RATIO = 0.3  # Assumes 70% Water\n",
    "flux_scaling_factor = 1e-3 * (GDW_GWW_RATIO * DENSITY) * CONCENTRATION_SCALING / TIME_SCALING\n",
    "NCPU = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = configs['PATHS']['model_file']\n",
    "thermo_experiment_file = configs['PATHS']['thermo_experiment_file']\n",
    "regulation_file = configs['PATHS']['regulation_file']\n",
    "kinetic_params_file = configs['PATHS']['kinetic_params_file']\n",
    "steady_states_file = configs['PATHS']['steady_states_file']\n",
    "steady_states_sample = 1712 #[1715,1717,2392,2482,3927,4230,4241,4456, 4468]\n",
    "\n",
    "path_to_kmodel = f'{base}/{met_model}/kinetic/{model_file}'\n",
    "path_to_tmodel = f'{base}/{met_model}/thermo/{thermo_experiment_file}'\n",
    "path_to_params = f'{base}/{met_model}/parameters/gen_{repeat}_{generation}_parameters.hdf5'\n",
    "path_to_regulation_data = f'{base}/{met_model}/{regulation_file}'\n",
    "path_to_samples = f'{base}/{met_model}/steady_state_samples/{steady_states_file}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "tmodel = load_json_model(path_to_tmodel)\n",
    "kmodel_draft = load_yaml_model(path_to_kmodel)\n",
    "\n",
    "# Add regulation data to kinetic model\n",
    "df = pd.read_csv(path_to_regulation_data)\n",
    "df_regulations_all = df[df['reaction_id'].isin(list(kmodel_draft.reactions.keys()))]\n",
    "df_regulations_all = df_regulations_all[df_regulations_all['regulator'].isin(list(kmodel_draft.reactants.keys()))]\n",
    "kmodel = load_enzyme_regulation(kmodel_draft, df_regulations_all)\n",
    "\n",
    "# Compile model\n",
    "kmodel.prepare()\n",
    "kmodel.compile_jacobian(ncpu=NCPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_idx = steady_states_sample \n",
    "samples = pd.read_csv(path_to_samples, header=0, index_col=0).iloc[ss_idx, 0:]\n",
    "\n",
    "flux_series = load_fluxes(samples, tmodel, kmodel,\n",
    "                  density=DENSITY,\n",
    "                  ratio_gdw_gww=GDW_GWW_RATIO,\n",
    "                  concentration_scaling=CONCENTRATION_SCALING,\n",
    "                  time_scaling=TIME_SCALING)\n",
    "\n",
    "conc_series = load_concentrations(samples, tmodel, kmodel,\n",
    "                          concentration_scaling=CONCENTRATION_SCALING)\n",
    "    \n",
    "# Fetch equilibrium constants\n",
    "k_eq = load_equilibrium_constants(samples, tmodel, kmodel,\n",
    "                          concentration_scaling=CONCENTRATION_SCALING,\n",
    "                          in_place=True)\n",
    "\n",
    "\n",
    "sampling_parameters = SimpleParameterSampler.Parameters(n_samples=1)\n",
    "sampler = SimpleParameterSampler(sampling_parameters)\n",
    "sampler._compile_sampling_functions(kmodel, conc_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_set = pd.DataFrame(np.exp(gen_params))\n",
    "parameter_set.columns = names_km\n",
    "\n",
    "param_population = []\n",
    "for j in range(len(parameter_set.index)):\n",
    "    param_val = parameter_set.loc[j] * CONCENTRATION_SCALING\n",
    "    param_sample, eigen = calc_eigenvalues(kmodel, param_val, flux_series, conc_series, k_eq)\n",
    "    param_population.append(param_sample)\n",
    "\n",
    "param_population = ParameterValuePopulation(param_population, kmodel=kmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bioreactor Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimpy.simulations.reactor import make_batch_reactor\n",
    "from renaissance.simulation.reactor import simulate_bioreactor\n",
    "import time\n",
    "\n",
    "# Ode simulation parameters\n",
    "TOTAL_TIME = 60\n",
    "N_STEPS = 1000\n",
    "MAX_TIME = 60\n",
    "REACTOR_VOLUME = 50e13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reactor initialization\n",
    "kinetic_models = list(param_population._index.keys())\n",
    "reactor = make_batch_reactor('../2_bioreactor/single_species.yaml', df_regulation= df_regulations_all)\n",
    "reactor.compile_ode(ncpu=NCPU, add_dilution=False)\n",
    "reactor_volume = reactor.models.strain_1.parameters.strain_1_volume_e.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sols_wt= []\n",
    "finals = {}\n",
    "for this_model in kinetic_models:\n",
    "    print(\"\\nRunning model: {}\".format(this_model))\n",
    "\n",
    "    # Load tfa sample and kinetic parameters into kinetic model\n",
    "    parameter_set = param_population[this_model]\n",
    "        \n",
    "    solution, final_biomass, final_anthranilate, final_glucose = \\\n",
    "    simulate_bioreactor(parameter_set, \n",
    "                        samples, \n",
    "                        kmodel, \n",
    "                        conc_series, \n",
    "                        reactor, \n",
    "                        reactor_volume=REACTOR_VOLUME,\n",
    "                        max_time=MAX_TIME,\n",
    "                        total_time=TOTAL_TIME,\n",
    "                        steps=N_STEPS)\n",
    "    finals[this_model] = [final_biomass, final_anthranilate, final_glucose]\n",
    "    sols_wt.append(solution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Experimental Value\n",
    "growth = pd.read_csv('../data/experimental_data/biomass_wt.csv')\n",
    "glc = pd.read_csv('../data/experimental_data/glc_wt.csv')\n",
    "anth = pd.read_csv('../data/experimental_data/anth_wt.csv')\n",
    "glc[glc.columns[1]] -= 0.54\n",
    "glc[glc.columns[2]] -= 0.54\n",
    "glc[glc.columns[3]] -= 0.54\n",
    "dict_scaling = {'biomass_strain_1': 0.28e-12/0.5, \n",
    "                'anth_e': 136.13 * 1e-9, \n",
    "                'glc_D_e': 1e-9 * 180.156}\n",
    "labels = {'biomass_strain_1': 'biomass (g)', 'anth_e': 'anthranilate (g/L)', 'glc_D_e': 'glucose (g/L)'}\n",
    "exp_data = {'biomass_strain_1': growth, 'anth_e': anth, 'glc_D_e': glc}\n",
    "T = np.linspace(0, TOTAL_TIME, N_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 10\n",
    "all_sols = sols_wt\n",
    "plt.figure(figsize = (10,25))\n",
    "plt.title('Generation', fontsize = 50)\n",
    "ix=1\n",
    "final_biomass = []\n",
    "final_anth = []\n",
    "final_glc = []\n",
    "\n",
    "for conc, scaling in dict_scaling.items():\n",
    "    \n",
    "    plt.subplot(5,1,ix)\n",
    "\n",
    "    # Plot simulated data\n",
    "\n",
    "    for sol_id in range(n_simulations):\n",
    "        this_sol = all_sols[sol_id].concentrations\n",
    "        if this_sol.shape[0]==N_STEPS:\n",
    "            plt.plot(T, this_sol[conc]*scaling, color = 'green', alpha = 0.5)\n",
    "        if conc== 'biomass_strain_1': final_biomass.append(list(this_sol[conc]*scaling)[-1])\n",
    "        if conc== 'anth_e':  final_anth.append(list(this_sol[conc]*scaling)[-1])\n",
    "        if conc== 'glc_D_e':  final_glc.append(list(this_sol[conc]*scaling)[-1])\n",
    "        \n",
    "    # Plot experimental data (when available)\n",
    "    \n",
    "    exp_ = exp_data[conc]\n",
    "    mean = exp_[exp_.columns[1]]\n",
    "    time_exp = exp_[exp_.columns[0]]\n",
    "\n",
    "    if len(exp_.columns) > 2:\n",
    "        lo = exp_[exp_.columns[2]]\n",
    "        hi = exp_[exp_.columns[3]]\n",
    "        plt.errorbar(time_exp, mean, yerr=np.asarray([mean - lo, hi - mean]),\n",
    "                     fmt='ko', label= f'{conc}', capsize=5)\n",
    "    else:\n",
    "        plt.plot(time_exp, mean, 'ko', label=f'{conc}')  \n",
    "\n",
    "    if conc== 'biomass_strain_1': plt.title(f'max biomass: {np.round(np.max(final_biomass),4)}')\n",
    "    \n",
    "    else: plt.title(f'{conc}')\n",
    "\n",
    "    \n",
    "    plt.xlabel('time (h)')\n",
    "    plt.ylabel(labels[conc])\n",
    "    plt.xlim([0, 60])\n",
    "    ix+=1\n",
    "  \n",
    "\n",
    "#plt.savefig(f'{plot_output}/bioreactor_results.jpg',dpi = 300, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate NRMSE\n",
    "def nrmse_score(errors, scaling_factor):\n",
    "    nrmse = 1 / (np.exp(errors / scaling_factor))**2\n",
    "    return nrmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stamp_matching(N_STEPS, TOTAL_TIME, current_time):\n",
    "    if current_time > TOTAL_TIME:\n",
    "        return N_STEPS\n",
    "    else:\n",
    "        return int(current_time * (N_STEPS-1) / TOTAL_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_last_points = 1\n",
    "\n",
    "all_solutions = exp_data.copy()\n",
    "total_reward = 0\n",
    "for conc, scaling in dict_scaling.items():\n",
    "    df = all_solutions[conc][['Time', 'mean']].iloc[-n_last_points:].copy()\n",
    "    df.rename(columns={'mean':'experimental'}, inplace=True)\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "    for i in range(10):\n",
    "        sim_conc = all_sols[i].concentrations[conc]\n",
    "\n",
    "        if sim_conc.shape[0]==N_STEPS:\n",
    "            new_df = df.copy() \n",
    "            new_df['simulated'] = new_df['Time'].apply(lambda x: sim_conc[time_stamp_matching(N_STEPS, TOTAL_TIME, x)]*scaling)\n",
    "            new_df['sq_err'] = (new_df['experimental'] - new_df['simulated']) ** 2\n",
    "            new_df['reward'] = nrmse_score(new_df['sq_err'], 0.5)\n",
    "            temp_df = temp_df.append(new_df, ignore_index=True)  # Append to temp_df\n",
    "    all_solutions[conc] = temp_df\n",
    "\n",
    "    total_reward += temp_df['reward'].mean() / 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from permetrics import RegressionMetric\n",
    "\n",
    "last_n_points = 5\n",
    "evaluator = RegressionMetric()\n",
    "\n",
    "full_score = {}\n",
    "for i in range(n_simulations):\n",
    "    sum = 0\n",
    "    for conc, scaling in dict_scaling.items():\n",
    "        sim_conc =all_sols[i].concentrations[conc]\n",
    "        if sim_conc.shape[0]==N_STEPS:\n",
    "            time_points = exp_data[conc]['Time'][-last_n_points:].values\n",
    "            exp_final_value = exp_data[conc]['mean'][-last_n_points:].values\n",
    "            sampling_time = [time_stamp_matching(N_STEPS, TOTAL_TIME, t) for t in time_points]\n",
    "            sim_final_value = sim_conc[sampling_time].values*scaling\n",
    "            score = nrmse_score(sim_final_value, exp_final_value, np.max(exp_final_value))\n",
    "            print(f'RMSE of model {i}: {conc}: {score}')\n",
    "            sum += score\n",
    "    full_score[i] = sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from renaissance.evostrat.rewards import check_simulated_RMSE\n",
    "check_simulated_RMSE(all_sols, exp_data, dict_scaling, N_STEPS, TOTAL_TIME, last_n_points)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
